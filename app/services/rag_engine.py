# app/services/rag_engine.py
import qdrant_client
from llama_index.vector_stores.qdrant import QdrantVectorStore
from llama_index.core import VectorStoreIndex, StorageContext
from app.core.config import get_settings
from app.services.llm_factory import ModelFactory
from functools import lru_cache # ğŸ‘ˆ å¯¼å…¥ç¼“å­˜è£…é¥°å™¨
from qdrant_client import models

settings = get_settings()
@lru_cache() # ğŸ‘ˆ åŠ ä¸Šè¿™ä¸ªè£…é¥°å™¨ï¼Œç¡®ä¿å…¨å±€åªåˆå§‹åŒ–ä¸€æ¬¡ Index å’Œ è¿æ¥
def get_index():
    """è·å–å…¨å±€å”¯ä¸€çš„ Index å¯¹è±¡"""
    # 1. è¿æ¥å®¢æˆ·ç«¯
    # å»ºç«‹åŒå®¢æˆ·ç«¯ï¼šåŒæ­¥ç”¨äºæ™®é€šæ“ä½œï¼Œå¼‚æ­¥ç”¨äºé«˜å¹¶å‘æ£€ç´¢
    print("ğŸ”Œ è¿æ¥ Qdrant ...")
    client = qdrant_client.QdrantClient(url=settings.QDRANT_URL)
    aclient = qdrant_client.AsyncQdrantClient(url=settings.QDRANT_URL)

    # ğŸŸ¢ æ–°å¢ï¼šæ£€æŸ¥å¹¶è‡ªåŠ¨åˆ›å»ºé›†åˆ
    if not client.collection_exists(collection_name=settings.COLLECTION_NAME):
        print(f"âš ï¸ é›†åˆ {settings.COLLECTION_NAME} ä¸å­˜åœ¨ï¼Œæ­£åœ¨è‡ªåŠ¨åˆ›å»º...")
        try:
            client.create_collection(
                collection_name=settings.COLLECTION_NAME,
                # 1. å¯†é›†å‘é‡é…ç½® (BGE-Large-zh-v1.5 ç»´åº¦ä¸º 1024)
                vectors_config=models.VectorParams(
                    size=1024, 
                    distance=models.Distance.COSINE
                ),
                # 2. ç¨€ç–å‘é‡é…ç½® (å¼€å¯ hybrid å¿…é¡»é…ç½®è¿™ä¸ª)
                # LlamaIndex é»˜è®¤ä½¿ç”¨çš„ç¨€ç–å‘é‡å­—æ®µåä¸º "text-sparse"
                sparse_vectors_config={
                    "text-sparse": models.SparseVectorParams(
                        index=models.SparseIndexParams(
                            on_disk=False,
                        )
                    )
                }
            )
            print("âœ… é›†åˆåˆ›å»ºæˆåŠŸï¼")
        except Exception as e:
            print(f"âŒ åˆ›å»ºé›†åˆå¤±è´¥: {e}")
            # å¦‚æœåˆ›å»ºå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸ï¼Œé˜²æ­¢åç»­é€»è¾‘æŠ¥é”™
            raise e

    # 2. å®šä¹‰å­˜å‚¨åç«¯
    vector_store = QdrantVectorStore(
        client=client,
        aclient=aclient,
        collection_name=settings.COLLECTION_NAME,
        enable_hybrid=True, # å¼€å¯æ··åˆæ£€ç´¢ (å…³é”®è¯+å‘é‡)
        # batch_size=20,    # å¦‚æœæŠ¥é”™å†…å­˜ä¸è¶³ï¼Œå¯ä»¥è°ƒå°è¿™ä¸ª
    )
    
    # 3. ç»„è£…ä¸Šä¸‹æ–‡
    storage_context = StorageContext.from_defaults(vector_store=vector_store)
    print("âœ… Qdrant è¿æ¥æˆåŠŸ")
    
    # 4. è¿”å› Index (æ³¨æ„ï¼šè¿™é‡Œå¿…é¡»ä¼ å…¥ embed_modelï¼Œå¦åˆ™å®ƒä¼šå»ä¸‹ OpenAI çš„)
    return VectorStoreIndex.from_vector_store(
        vector_store=vector_store,
        embed_model=ModelFactory.get_embed_model() # è°ƒç”¨ä¸Šé¢çš„å·¥å‚
    )
